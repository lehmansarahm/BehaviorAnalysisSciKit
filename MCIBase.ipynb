{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class MCI_Constants(object):\n",
    "    # ------------------------------------------------------------------\n",
    "    #    Directories\n",
    "    # ------------------------------------------------------------------\n",
    "    DATASETS_MCI = \"datasets/mci\"\n",
    "    OUTPUT = \"output\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #     Training files\n",
    "    # ------------------------------------------------------------------\n",
    "    YA_SINGLE_BREAKFAST_SCOOP = \"YA-Single-Breakfast-Scoop-Aggregate.csv\"\n",
    "    YA_SINGLE_BREAKFAST_SELECT = \"YA-Single-Breakfast-Select-Aggregate.csv\"\n",
    "    YA_SINGLE_BREAKFAST_SELECT_STIR_SCOOP = \"YA-Single-Breakfast-Select-Stir-Scoop-Aggregate.csv\"\n",
    "    YA_SINGLE_BREAKFAST_STIR = \"YA-Single-Breakfast-Stir-Aggregate.csv\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #     Testing files\n",
    "    # ------------------------------------------------------------------\n",
    "    OA_BREAKFAST_SCOOP = \"OA-Breakfast-Scoop-Aggregate.csv\"\n",
    "    OA_BREAKFAST_SELECT = \"OA-Breakfast-Select-Aggregate.csv\"\n",
    "    OA_BREAKFAST_STIR = \"OA-Breakfast-Stir-Aggregate.csv\"\n",
    "    YA_SINGLE_LUNCH_SCOOP = \"YA-Single-Lunch-Scoop-Aggregate.csv\"\n",
    "    YA_SINGLE_LUNCH_SELECT = \"YA-Single-Lunch-Select-Aggregate.csv\"\n",
    "    YA_SINGLE_LUNCH_STIR = \"YA-Single-Lunch-Stir-Aggregate.csv\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #     Input files\n",
    "    # ------------------------------------------------------------------\n",
    "    OA_BREAKFAST = \"OA-Breakfast.csv\"\n",
    "    YA_SINGLE_LUNCH = \"YA-Single-Lunch.csv\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #     Classifier model file paths\n",
    "    # ------------------------------------------------------------------\n",
    "    def get_nearest_neighbors_clf_path(task_name):\n",
    "        return os.path.join(\"models\", task_name, \"knnCLF.joblib.pkl\")\n",
    "    def get_random_forest_clf_path(task_name):\n",
    "        return os.path.join(\"models\", task_name, \"rfCLF.joblib.pkl\")\n",
    "    def get_svm_clf_path(task_name):\n",
    "        return os.path.join(\"models\", task_name, \"svmCLF.joblib.pkl\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #     DEFAULTS\n",
    "    # ------------------------------------------------------------------\n",
    "    DEFAULT_DATASET_PATH = DATASETS_MCI\n",
    "    DEFAULT_INPUT_FILENAME = OA_BREAKFAST\n",
    "    DEFAULT_OUTPUT_DIR = OUTPUT\n",
    "    DEFAULT_TRAIN_FILE = YA_SINGLE_BREAKFAST_SELECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# base data load function\n",
    "# returns CSV file as a Pandas data frame\n",
    "def load_mci_file(dataset_path=MCI_Constants.DEFAULT_DATASET_PATH, filename=MCI_Constants.DEFAULT_TRAIN_FILE):\n",
    "    csv_path = os.path.join(dataset_path, filename)\n",
    "    return pd.read_csv(csv_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output_file(filename, data):\n",
    "    output_path = os.path.join(MCI_Constants.DEFAULT_OUTPUT_DIR, filename)\n",
    "    final_data = \"\\n\".join(filter(None, data))\n",
    "    # print(final_data)\n",
    "    \n",
    "    f = open(output_path, 'w+')\n",
    "    f.write(final_data)\n",
    "    f.close\n",
    "    \n",
    "    print(\"Output written to file at:\", output_path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# retrieve the value fields and subsequent labels we want to process\n",
    "def get_value_label_matrices(data_set):\n",
    "    train_labels = data_set[\"Label\"].copy().as_matrix()\n",
    "    train_values_raw = data_set[[\n",
    "        \"Mean-Mag\", \n",
    "        \"Variance-Mag\", \n",
    "        \"Skewness-Mag\", \n",
    "        \"Kurtosis-Mag\", \n",
    "        \"RMS-Mag\"]].copy().as_matrix()\n",
    "\n",
    "    # scale sample values\n",
    "    scaler = StandardScaler()\n",
    "    train_values = scaler.fit_transform(train_values_raw.astype(np.float64))\n",
    "\n",
    "    # should match\n",
    "    print(len(train_values), \"values + \", len(train_labels), \"labels\") \n",
    "    return train_values, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# double check to make sure the records we know about return the correct results\n",
    "def verify_known_values(clf, train_set, train_values, print_sample_info=True):\n",
    "    # ------------------------------------------------------------------\n",
    "    #     Known \"Select\" sample\n",
    "    # ------------------------------------------------------------------\n",
    "    ya8_select_coffee_orig = train_set.as_matrix()[3]\n",
    "    ya8_select_coffee = train_values[3] \n",
    "    if (print_sample_info):\n",
    "        print(\"\")\n",
    "        print(\"Sample name (YA8 select-coffee):\", ya8_select_coffee_orig[0])\n",
    "        print(\"Orig mean (0.833351):\", ya8_select_coffee_orig[4])\n",
    "        print(\"Scaled mean (0.09575075):\", ya8_select_coffee[0])\n",
    "        print(ya8_select_coffee)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #     Known \"Stir\" sample\n",
    "    # ------------------------------------------------------------------\n",
    "    ya11_stir_mug2_orig = train_set.as_matrix()[24]\n",
    "    ya11_stir_mug2 = train_values[0] \n",
    "    if (print_sample_info):\n",
    "        print(\"\")\n",
    "        print(\"Sample name (YA11 stir-mug-2):\", ya11_stir_mug2_orig[0])\n",
    "        print(\"Orig mean (0.816233):\", ya11_stir_mug2_orig[4])\n",
    "        print(\"Scaled mean (-0.13537523):\", ya11_stir_mug2[0])\n",
    "        print(ya11_stir_mug2)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    #     Known \"Scoop\" sample\n",
    "    # ------------------------------------------------------------------\n",
    "    ya5_scoop_orig = train_set.as_matrix()[12]\n",
    "    ya5_scoop = train_values[3] \n",
    "    if (print_sample_info):\n",
    "        print(\"\")\n",
    "        print(\"Sample name (YA5 scoop-and-spread-butter):\", ya5_scoop_orig[0])\n",
    "        print(\"Orig mean (0.890791):\", ya5_scoop_orig[4])\n",
    "        print(\"Scaled mean (0.09575075):\", ya5_scoop[0])\n",
    "        print(ya5_scoop)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #     Confirm predictions\n",
    "    # ------------------------------------------------------------------\n",
    "    print(\"\")\n",
    "    prediction = clf.predict([ya8_select_coffee]) \n",
    "    print(\"Prediction for YA8 select-coffee:\", prediction)\n",
    "    prediction = clf.predict([ya11_stir_mug2]) \n",
    "    print(\"Prediction for YA11 stir-mug-2:\", prediction)\n",
    "    prediction = clf.predict([ya5_scoop]) \n",
    "    print(\"Prediction for YA5 scoop-and-spread-butter:\", prediction)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# cross validate classifier predictions for a set of values and expected labels\n",
    "# returns set of predicted labels\n",
    "def cross_validate(clf, values, labels, is_multi=False):\n",
    "    validator_num = 20\n",
    "    scoring_method = \"accuracy\"\n",
    "    \n",
    "    predicted_labels = cross_val_predict(clf, values, labels, cv=validator_num)\n",
    "    if (not is_multi):\n",
    "        actual_preds = confusion_matrix(labels, predicted_labels)\n",
    "        perfect_preds = confusion_matrix(labels, labels)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Actual Predictions:\")\n",
    "        print(actual_preds)\n",
    "        print(\"Perfect Predictions:\")\n",
    "        print(perfect_preds)\n",
    "    \n",
    "    score = cross_val_score(clf, values, labels, cv=validator_num, scoring=scoring_method)\n",
    "    print(\"\")\n",
    "    print(\"Classifier accuracy:\", score)\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# ------------------------------------------\n",
    "#\n",
    "# PRECISION:\n",
    "# What percentage of the time is a positive hit truly an accurate hit\n",
    "#\n",
    "# ------------------------------------------\n",
    "#\n",
    "# RECALL:\n",
    "# What percentage of true positives are found\n",
    "#\n",
    "# ------------------------------------------\n",
    "#\n",
    "# F-SCORE:\n",
    "# Harmonic mean of precision and recall\n",
    "#\n",
    "# ------------------------------------------\n",
    "\n",
    "# calculating precision, recall, and f-score for a set of predicted labels vs. actual labels\n",
    "def evaluate_predictions(task_labels, label_predictions, is_multi=False):\n",
    "    if (not is_multi):\n",
    "        precision = precision_score(task_labels, label_predictions)\n",
    "        recall = recall_score(task_labels, label_predictions)\n",
    "        fscore = f1_score(task_labels, label_predictions)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Default Precision:\", precision)\n",
    "        print(\"Default Recall:\", recall)\n",
    "        print(\"Default F-score:\", fscore)\n",
    "\n",
    "    precision = precision_score(task_labels, label_predictions, average='micro')\n",
    "    recall = recall_score(task_labels, label_predictions, average='micro')\n",
    "    fscore = f1_score(task_labels, label_predictions, average='micro')\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Micro Precision:\", precision)\n",
    "    print(\"Micro Recall:\", recall)\n",
    "    print(\"Micro F-score:\", fscore)\n",
    "\n",
    "    precision = precision_score(task_labels, label_predictions, average='macro')\n",
    "    recall = recall_score(task_labels, label_predictions, average='macro')\n",
    "    fscore = f1_score(task_labels, label_predictions, average='macro')\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Macro Precision:\", precision)\n",
    "    print(\"Macro Recall:\", recall)\n",
    "    print(\"Macro F-score:\", fscore)\n",
    "\n",
    "    precision = precision_score(task_labels, label_predictions, average='weighted')\n",
    "    recall = recall_score(task_labels, label_predictions, average='weighted')\n",
    "    fscore = f1_score(task_labels, label_predictions, average='weighted')\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Weighted Precision:\", precision)\n",
    "    print(\"Weighted Recall:\", recall)\n",
    "    print(\"Weighted F-score:\", fscore)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the dataset into training (80%) and testing (20%) partitions\n",
    "def split_train_test_matrices(dataset):\n",
    "    train_set, test_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "    print(len(train_set), \"train +\", len(test_set), \"test\")\n",
    "\n",
    "    # from the original training set, parse out the values / labels\n",
    "    train_values, train_labels = get_value_label_matrices(train_set)\n",
    "    test_values, test_labels = get_value_label_matrices(test_set)\n",
    "    return train_values, train_labels, test_values, test_labels\n",
    "\n",
    "# get cross-val predictions from a single classifier\n",
    "def cross_validate_classifier_predictions(clf, values, labels):\n",
    "    # cross validation with confusion matrix\n",
    "    predicted_labels = cross_validate(clf, values, labels)\n",
    "    # calculating precision, recall, and f-score\n",
    "    evaluate_predictions(labels, predicted_labels)\n",
    "    return\n",
    "\n",
    "def validate_classifier_predictions(clf, values, labels):\n",
    "    predicted_labels = clf.predict(values)\n",
    "    evaluate_predictions(labels, predicted_labels)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# apply random forest classifier to training set\n",
    "def train_rf_classifier(values, labels, limit_label=None, estimators=100):\n",
    "    if (limit_label is not None):\n",
    "        labels = (labels == limit_label)\n",
    "    \n",
    "    rfCLF = RandomForestClassifier(n_estimators=estimators) # 100)\n",
    "    rfCLF = rfCLF.fit(values, labels) # train_values, train_labels)\n",
    "    cross_validate_classifier_predictions(rfCLF, values, labels)\n",
    "    return rfCLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# apply SVM classifier to training set\n",
    "def train_svm_classifier(values, labels, limit_label=None):\n",
    "    if (limit_label is not None):\n",
    "        labels = (labels == limit_label)\n",
    "    \n",
    "    svmCLF = svm.SVC()\n",
    "    svmCLF.fit(values, labels) \n",
    "    cross_validate_classifier_predictions(svmCLF, values, labels)\n",
    "    return svmCLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# apply nearest neighbors classifier to training set\n",
    "def train_knn_classifier(values, labels, limit_label=None, n_neighbors=3):\n",
    "    if (limit_label is not None):\n",
    "        labels = (labels == limit_label)\n",
    "    \n",
    "    knnCLF = KNeighborsClassifier(n_neighbors)\n",
    "    knnCLF = knnCLF.fit(values, labels)\n",
    "    cross_validate_classifier_predictions(knnCLF, values, labels)\n",
    "    return knnCLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_trained_classifier_predictions(data_set, clf):\n",
    "    values, labels = get_value_label_matrices(data_set)\n",
    "    predictions = clf.predict(values)\n",
    "    \n",
    "    results = [ None ] * (len(data_set) + 1)\n",
    "    results[0] = \"Source,Prediction\"\n",
    "    \n",
    "    for i in range (0, len(data_set) - 1):\n",
    "        data_item = data_set.as_matrix()[i]\n",
    "        results[i+1] = str(data_item[0]) + \",\" + str(predictions[i])\n",
    "        # print(\"Source:\", data_item[0], \"Prediction:\", predictions[i])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "def write_clf_to_file(clf, filename):\n",
    "    _ = joblib.dump(clf, filename, compress=9)\n",
    "    return\n",
    "\n",
    "def load_clf_from_file(filename):\n",
    "    clf2 = joblib.load(filename)\n",
    "    return clf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(\"# ---------------------------------------------------\")\n",
    "# print(\"    K-NEAREST WITH MULTI-CLASS LABELS    \")\n",
    "# print(\"# ---------------------------------------------------\")\n",
    "\n",
    "# primary_task_labels = (train_labels == 1)\n",
    "# secondary_task_labels = (train_labels == 2)\n",
    "# tertiary_task_labels = (train_labels == 3)\n",
    "# train_labels_multi = np.c_[primary_task_labels, secondary_task_labels, tertiary_task_labels]\n",
    "\n",
    "# knnCLF = knnCLF.fit(train_values, train_labels_multi)\n",
    "# verify_known_values(knnCLF, train_set, train_values, False)\n",
    "\n",
    "# predicted_labels = cross_validate(knnCLF, train_values, train_labels_multi, True)\n",
    "# evaluate_predictions(train_labels_multi, predicted_labels, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
